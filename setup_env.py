#!/usr/bin/env python3
"""
Script para configurar vari√°veis de ambiente para PySpark no VSCode
"""
import os
import sys
import subprocess

def setup_java_env():
    """Configura as vari√°veis de ambiente do Java para PySpark"""
    
    # Poss√≠veis localiza√ß√µes do Java
    java_paths = [
        "/opt/homebrew/opt/openjdk@11",
        "/opt/homebrew/opt/openjdk@8", 
        "/usr/libexec/java_home",
        "/Library/Java/JavaVirtualMachines"
    ]
    
    java_home = None
    
    # Tentar encontrar Java via java_home
    try:
        result = subprocess.run(["/usr/libexec/java_home", "-v", "11"], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            java_home = result.stdout.strip()
            print(f"‚úÖ Java encontrado via java_home: {java_home}")
    except:
        pass
    
    # Se n√£o encontrou, tentar Homebrew
    if not java_home:
        for path in java_paths:
            if os.path.exists(path) and "homebrew" in path:
                java_home = path
                print(f"‚úÖ Java encontrado no Homebrew: {java_home}")
                break
    
    if java_home:
        # Configurar vari√°veis de ambiente
        os.environ["JAVA_HOME"] = java_home
        os.environ["PATH"] = f"{java_home}/bin:{os.environ.get('PATH', '')}"
        
        # Para PySpark
        os.environ["PYSPARK_SUBMIT_ARGS"] = "--master local[*] pyspark-shell"
        
        print(f"üîß JAVA_HOME configurado: {java_home}")
        print(f"üîß PATH atualizado")
        
        return True
    else:
        print("‚ùå Java n√£o encontrado!")
        print("Instale o Java com: brew install openjdk@11")
        return False

def test_spark():
    """Testa se o Spark est√° funcionando"""
    try:
        import findspark
        findspark.init()
        
        from pyspark.sql import SparkSession
        
        spark = SparkSession.builder \
            .appName("TestSpark") \
            .master("local[*]") \
            .config("spark.sql.adaptive.enabled", "true") \
            .getOrCreate()
        
        # Teste simples
        df = spark.createDataFrame([(1, "test")], ["id", "name"])
        count = df.count()
        
        spark.stop()
        
        print(f"‚úÖ Spark funcionando! Teste executado com sucesso (count: {count})")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro no Spark: {e}")
        return False

if __name__ == "__main__":
    print("üöÄ Configurando ambiente PySpark...")
    
    if setup_java_env():
        print("‚òï Java configurado com sucesso!")
        
        if test_spark():
            print("‚ö° Spark testado com sucesso!")
            print("\n‚úÖ Ambiente pronto para usar!")
        else:
            print("\n‚ùå Problema com Spark")
    else:
        print("\n‚ùå Problema com Java")
